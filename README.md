# tinyOCR
I'm studying transformers by making a tiny OCR model.

# My plan
Here's what I'm going to do. 
1. make a ViT model. 
2. pretrain as a masked autoencoder.
3. Implement BLIP-2 with the ViT model.
4. consider OCR texts as image captions and predict OCR texts from images with the BLIP-2 model.

I'm going to make the model small enough that I can run the training on one ore two GPUs.

# references
(to be added)